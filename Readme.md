# ğŸ§  NeuroMaze: Adaptive Puzzleverse ğŸ®

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue?logo=python" alt="Python"/>
  <img src="https://img.shields.io/badge/FastAPI-Backend-green?logo=fastapi" alt="FastAPI"/>
  <img src="https://img.shields.io/badge/PyTorch-ML-orange?logo=pytorch" alt="PyTorch"/>
  <img src="https://img.shields.io/badge/License-MIT-yellow" alt="MIT License"/>
  <img src="https://img.shields.io/badge/Made with-â¤-maroon" alt="Made with Love">
  <img src="https://img.shields.io/badge/Status-Alpha-orange" alt="Development Status">
</p>

> **NeuroMaze** is an AI-powered puzzle game that adapts itself in real-time based on your emotional state and playstyle. Combining game design, AI, and emotion detection, it delivers a truly personalized gameplay experience.

## âœ¨ Features

- ğŸ¤– **Real-Time Emotion Detection** â€” Uses your webcam to sense stress, confusion, or excitement
- ğŸ§© **Dynamic Puzzle Generation** â€” Mazes and puzzles evolve in complexity as you play
- ğŸ§  **Player Behavior Profiling** â€” Learns your style: solver, explorer, rusher, tinkerer
- ğŸ—£ï¸ **AI-Powered Game Narrator** â€” The in-game voice adapts its tone to your behavior and emotions
- ğŸŒ **WebGL-Ready** â€” Playable in browser for demo and portfolio

## ğŸ“¸ Demo

> _Coming soon! We're working on a gameplay demo video to showcase NeuroMaze's adaptive features._

## ğŸš€ Quickstart

```bash
# 1. Clone the repo
git clone https://github.com/Kira262/NeuroMaze.git
cd NeuroMaze

# 2. Install dependencies
pip install -r requirements.txt

# 3. Start the backend (FastAPI)
cd ai-backend
uvicorn main:app --reload

# 4. Run the emotion detector
cd ../emotion_detector
python detect_emotion.py

# 5. Start the game (Pygame)
cd ../game
python game.py
```

## ğŸ› ï¸ Tech Stack

| Area              | Technologies                                      |
|-------------------|--------------------------------------------------|
| Game Engine       | Pygame (Python)                                  |
| Emotion Detection | OpenCV, MediaPipe, PyTorch CNN                   |
| Backend API       | FastAPI, Uvicorn                                 |
| AI Models         | PyTorch (Emotion Classification, Behavior Modeling) |
| Communication     | REST API                                         |
| Hosting           | (Planned) WebGL, Render/Vercel                   |

## ğŸ“¦ Project Structure

```
NeuroMaze/
â”œâ”€â”€ ai-backend/         # FastAPI backend for difficulty logic
â”œâ”€â”€ emotion_detector/   # Real-time emotion detection
â”œâ”€â”€ game/               # Pygame-based maze game
â”œâ”€â”€ assets/             # Art, audio, and UI assets
â”œâ”€â”€ demo/               # WebGL build or gameplay footage
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ Readme.md           # This file
```

## ğŸ§  How It Works

### System Architecture
```
[Webcam] â†’ [Emotion Detector] â†’ [AI Backend] â†’ [Game Difficulty & Feedback]
      |             |                  |                  |
      |             |                  |                  |
      +---[Face]    +---[Emotion]      +---[Difficulty]   +---[Adaptive Maze]
```

### Difficulty Levels

| Emotion    | Difficulty | Game Adjustments                          |
|------------|------------|-------------------------------------------|
| Happiness  | Easy       | Slower enemies, more health, longer time  |
| Anger      | Hard       | Faster enemies, less health, shorter time |
| Fear       | Easy       | Reduced challenge to ease tension         |
| Sadness    | Easy       | Reduced challenge to improve mood         |
| Surprise   | Normal     | Standard game parameters                  |
| Disgust    | Hard       | Increased challenge                       |
| Neutral    | Normal     | Standard game parameters                  |

## ğŸ§© Roadmap

- [x] Basic Maze Navigation
- [x] Emotion Detector Integration
- [x] Backend AI Logic
- [ ] Puzzle Room Template
- [ ] Unity â†” API Integration
- [ ] WebGL Build & Deployment

## ğŸ› ï¸ Prerequisites

- Python 3.8+
- Virtual environment (recommended)
- Webcam access
- Unity 2021.3+ (for future Unity integration)

## ğŸ¤ Contributing

1. Fork the repo
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a pull request

## ğŸ’¬ Getting Help

Having trouble? Here are some common solutions:

1. **Webcam Issues**
   - Ensure your webcam is properly connected and accessible
   - Check camera permissions in your system settings
   - Try a different camera if available

2. **Installation Problems**
   - Make sure you're using Python 3.8 or higher
   - Create a fresh virtual environment
   - Check the [issues page](https://github.com/Kira262/NeuroMaze/issues) for known problems

3. **Emotion Detection**
   - Ensure good lighting conditions
   - Position yourself properly in front of the camera
   - Check if the emotion model is properly loaded

For more help, please [open an issue](https://github.com/Kira262/NeuroMaze/issues/new) or join our community!

## ğŸ‘¤ Author

**Paavan**  
CSE Student | Full-stack Dev | AI Explorer  
[Portfolio](https://github.com/Kira262)

## ğŸ“œ License

MIT License â€“ Feel free to fork, remix, and build on top of this.

## ğŸ™ Acknowledgments

- MediaPipe for facial landmark detection
- PyTorch for the emotion recognition model
- FastAPI for the backend server
- Unity for the game engine
